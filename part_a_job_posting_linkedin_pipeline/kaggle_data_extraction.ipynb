{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType, StringType, TimestampType, DoubleType, LongType\n",
    "from pyspark.sql.functions import col, from_unixtime, floor\n",
    "\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials_location = \"/home/xiangivyli/data-science-portfolio/part_a_job_posting_linkedin_pipeline/airflow/include/.gc/airflow-gcp-bigquery.json\"\n",
    "\n",
    "jars_location = \"/home/xiangivyli/lib/gcs-connector-hadoop3-2.2.5.jar\"\n",
    "\n",
    "\n",
    "# First, stop the existing Spark session if it's running\n",
    "if 'spark' in locals():\n",
    "    spark.stop()\n",
    "\n",
    "# Configure the connection to gcs\n",
    "conf = SparkConf() \\\n",
    "    .setMaster('local[*]') \\\n",
    "    .setAppName('RepartitionParquetApp') \\\n",
    "    .set(\"spark.jars\", jars_location) \\\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\") \\\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", credentials_location)\n",
    "\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "hadoop_conf = sc._jsc.hadoopConfiguration()\n",
    "\n",
    "hadoop_conf.set(\"fs.AbstractFileSystem.gs.impl\",  \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "hadoop_conf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "hadoop_conf.set(\"fs.gs.auth.service.account.json.keyfile\", credentials_location)\n",
    "hadoop_conf.set(\"fs.gs.auth.service.account.enable\", \"true\")\n",
    "\n",
    "# Create or get a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .config(conf=sc.getConf()) \\\n",
    "    .config(\"spark.sql.parquet.int96RebaseModeInWrite\", \"LEGACY\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read data and check schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### job_postings.csv fact table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Spark schema\n",
    "job_postings_schema = StructType([\n",
    "    StructField(\"job_id\", StringType(), True),\n",
    "    StructField(\"company_id\", StringType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"description\", StringType(), True),\n",
    "    StructField(\"max_salary\", FloatType(), True),\n",
    "    StructField(\"med_salary\", FloatType(), True),\n",
    "    StructField(\"min_salary\", FloatType(), True),\n",
    "    StructField(\"pay_period\", StringType(), True),\n",
    "    StructField(\"formatted_work_type\", StringType(), True),\n",
    "    StructField(\"location\", StringType(), True),\n",
    "    StructField(\"applies\", IntegerType(), True),\n",
    "    StructField(\"original_listed_time\", LongType(), True),\n",
    "    StructField(\"remote_allowed\", StringType(), True),\n",
    "    StructField(\"views\", IntegerType(), True),\n",
    "    StructField(\"job_posting_url\", StringType(), True),\n",
    "    StructField(\"application_url\", StringType(), True),\n",
    "    StructField(\"application_type\", StringType(), True),\n",
    "    StructField(\"expiry\", LongType(), True),\n",
    "    StructField(\"closed_time\", LongType(), True),\n",
    "    StructField(\"formatted_experience_level\", StringType(), True),\n",
    "    StructField(\"skills_desc\", StringType(), True),\n",
    "    StructField(\"listed_time\", LongType(), True),\n",
    "    StructField(\"posting_domain\", StringType(), True),\n",
    "    StructField(\"sponsored\", IntegerType(), True),\n",
    "    StructField(\"work_type\", StringType(), True),\n",
    "    StructField(\"currency\", StringType(), True),\n",
    "    StructField(\"compensation_type\", StringType(), True),\n",
    "    StructField(\"scraped\", IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/03/30 08:39:33 WARN FileStreamSink: Assume no metadata directory. Error while looking for metadata directory in the path: gs://de-zoomcamp-xiangivyli/final_project/raw/job_postings.csv.\n",
      "java.io.IOException: Error accessing gs://de-zoomcamp-xiangivyli/final_project/raw/job_postings.csv\n",
      "\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getObject(GoogleCloudStorageImpl.java:2155)\n",
      "\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getItemInfo(GoogleCloudStorageImpl.java:2043)\n",
      "\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystem.getFileInfoInternal(GoogleCloudStorageFileSystem.java:1091)\n",
      "\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystem.getFileInfo(GoogleCloudStorageFileSystem.java:1065)\n",
      "\tat com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.getFileStatus(GoogleHadoopFileSystemBase.java:955)\n",
      "\tat org.apache.hadoop.fs.FileSystem.isDirectory(FileSystem.java:1777)\n",
      "\tat org.apache.spark.sql.execution.streaming.FileStreamSink$.hasMetadata(FileStreamSink.scala:54)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:228)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:210)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:210)\n",
      "\tat org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:537)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.json.GoogleJsonResponseException: 403 Forbidden\n",
      "GET https://storage.googleapis.com/storage/v1/b/de-zoomcamp-xiangivyli/o/final_project%2Fraw%2Fjob_postings.csv?fields=bucket,name,timeCreated,updated,generation,metageneration,size,contentType,contentEncoding,md5Hash,crc32c,metadata\n",
      "{\n",
      "  \"code\" : 403,\n",
      "  \"errors\" : [ {\n",
      "    \"domain\" : \"global\",\n",
      "    \"message\" : \"airflow-gcs-bigquery@cedar-style-412618.iam.gserviceaccount.com does not have storage.objects.get access to the Google Cloud Storage object. Permission 'storage.objects.get' denied on resource (or it may not exist).\",\n",
      "    \"reason\" : \"forbidden\"\n",
      "  } ],\n",
      "  \"message\" : \"airflow-gcs-bigquery@cedar-style-412618.iam.gserviceaccount.com does not have storage.objects.get access to the Google Cloud Storage object. Permission 'storage.objects.get' denied on resource (or it may not exist).\"\n",
      "}\n",
      "\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146)\n",
      "\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:118)\n",
      "\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:37)\n",
      "\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:428)\n",
      "\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1111)\n",
      "\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:514)\n",
      "\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:455)\n",
      "\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:565)\n",
      "\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getObject(GoogleCloudStorageImpl.java:2149)\n",
      "\t... 24 more\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o819.csv.\n: java.io.IOException: Error accessing gs://de-zoomcamp-xiangivyli/final_project/raw/job_postings.csv\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getObject(GoogleCloudStorageImpl.java:2155)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getItemInfo(GoogleCloudStorageImpl.java:2043)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystem.getFileInfoInternal(GoogleCloudStorageFileSystem.java:1091)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystem.getFileInfo(GoogleCloudStorageFileSystem.java:1065)\n\tat com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.getFileStatus(GoogleHadoopFileSystemBase.java:955)\n\tat org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1760)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$4(DataSource.scala:784)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$4$adapted(DataSource.scala:782)\n\tat org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:372)\n\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n\tat scala.util.Success.map(Try.scala:213)\n\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n\tat java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1426)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)\n\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)\n\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)\n\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)\n\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:177)\nCaused by: com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.json.GoogleJsonResponseException: 403 Forbidden\nGET https://storage.googleapis.com/storage/v1/b/de-zoomcamp-xiangivyli/o/final_project%2Fraw%2Fjob_postings.csv?fields=bucket,name,timeCreated,updated,generation,metageneration,size,contentType,contentEncoding,md5Hash,crc32c,metadata\n{\n  \"code\" : 403,\n  \"errors\" : [ {\n    \"domain\" : \"global\",\n    \"message\" : \"airflow-gcs-bigquery@cedar-style-412618.iam.gserviceaccount.com does not have storage.objects.get access to the Google Cloud Storage object. Permission 'storage.objects.get' denied on resource (or it may not exist).\",\n    \"reason\" : \"forbidden\"\n  } ],\n  \"message\" : \"airflow-gcs-bigquery@cedar-style-412618.iam.gserviceaccount.com does not have storage.objects.get access to the Google Cloud Storage object. Permission 'storage.objects.get' denied on resource (or it may not exist).\"\n}\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:118)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:37)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:428)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1111)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:514)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:455)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:565)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getObject(GoogleCloudStorageImpl.java:2149)\n\t... 21 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m df_posting \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread \\\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheader\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mescape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m.\u001b[39mschema(job_postings_schema) \\\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;241m.\u001b[39mcsv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgs://de-zoomcamp-xiangivyli/final_project/raw/job_postings.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/readwriter.py:535\u001b[0m, in \u001b[0;36mDataFrameReader.csv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(path) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark\u001b[38;5;241m.\u001b[39m_sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jreader\u001b[38;5;241m.\u001b[39mcsv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark\u001b[38;5;241m.\u001b[39m_sc\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mtoSeq(path)))\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, RDD):\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(iterator):\n",
      "File \u001b[0;32m~/spark/spark-3.3.2-bin-hadoop3/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/utils.py:190\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    192\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/spark/spark-3.3.2-bin-hadoop3/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o819.csv.\n: java.io.IOException: Error accessing gs://de-zoomcamp-xiangivyli/final_project/raw/job_postings.csv\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getObject(GoogleCloudStorageImpl.java:2155)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getItemInfo(GoogleCloudStorageImpl.java:2043)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystem.getFileInfoInternal(GoogleCloudStorageFileSystem.java:1091)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystem.getFileInfo(GoogleCloudStorageFileSystem.java:1065)\n\tat com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.getFileStatus(GoogleHadoopFileSystemBase.java:955)\n\tat org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1760)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$4(DataSource.scala:784)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$4$adapted(DataSource.scala:782)\n\tat org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:372)\n\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n\tat scala.util.Success.map(Try.scala:213)\n\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n\tat java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1426)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)\n\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)\n\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)\n\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)\n\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:177)\nCaused by: com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.json.GoogleJsonResponseException: 403 Forbidden\nGET https://storage.googleapis.com/storage/v1/b/de-zoomcamp-xiangivyli/o/final_project%2Fraw%2Fjob_postings.csv?fields=bucket,name,timeCreated,updated,generation,metageneration,size,contentType,contentEncoding,md5Hash,crc32c,metadata\n{\n  \"code\" : 403,\n  \"errors\" : [ {\n    \"domain\" : \"global\",\n    \"message\" : \"airflow-gcs-bigquery@cedar-style-412618.iam.gserviceaccount.com does not have storage.objects.get access to the Google Cloud Storage object. Permission 'storage.objects.get' denied on resource (or it may not exist).\",\n    \"reason\" : \"forbidden\"\n  } ],\n  \"message\" : \"airflow-gcs-bigquery@cedar-style-412618.iam.gserviceaccount.com does not have storage.objects.get access to the Google Cloud Storage object. Permission 'storage.objects.get' denied on resource (or it may not exist).\"\n}\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:118)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:37)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:428)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1111)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:514)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:455)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:565)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getObject(GoogleCloudStorageImpl.java:2149)\n\t... 21 more\n"
     ]
    }
   ],
   "source": [
    "df_posting = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"escape\", \"\\\"\") \\\n",
    "    .option(\"multiline\", \"true\") \\\n",
    "    .schema(job_postings_schema) \\\n",
    "    .csv(\"gs://de-zoomcamp-xiangivyli/final_project/raw/job_postings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/03/30 08:18:03 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------------------------------------------\n",
      " job_id                     | 3757940104                                         \n",
      " company_id                 | 553718                                             \n",
      " title                      | Hearing Care Provider                              \n",
      " description                | Overview\\n\\nHearingLife is a national hearing c... \n",
      " max_salary                 | null                                               \n",
      " med_salary                 | 5250.0                                             \n",
      " min_salary                 | null                                               \n",
      " pay_period                 | MONTHLY                                            \n",
      " formatted_work_type        | Full-time                                          \n",
      " location                   | Little River, SC                                   \n",
      " applies                    | null                                               \n",
      " original_listed_time       | null                                               \n",
      " remote_allowed             | null                                               \n",
      " views                      | 9                                                  \n",
      " job_posting_url            | https://www.linkedin.com/jobs/view/3757940104/?... \n",
      " application_url            | https://careers-demant.icims.com/jobs/19601/hea... \n",
      " application_type           | OffsiteApply                                       \n",
      " expiry                     | null                                               \n",
      " closed_time                | null                                               \n",
      " formatted_experience_level | Entry level                                        \n",
      " skills_desc                | null                                               \n",
      " listed_time                | null                                               \n",
      " posting_domain             | careers-demant.icims.com                           \n",
      " sponsored                  | 0                                                  \n",
      " work_type                  | FULL_TIME                                          \n",
      " currency                   | USD                                                \n",
      " compensation_type          | BASE_SALARY                                        \n",
      " scraped                    | 1699138101                                         \n",
      "-RECORD 1------------------------------------------------------------------------\n",
      " job_id                     | 3757940025                                         \n",
      " company_id                 | 2192142                                            \n",
      " title                      | Shipping & Receiving Associate 2nd shift (Beave... \n",
      " description                | Metalcraft of Mayville\\nMetalcraft of Mayville ... \n",
      " max_salary                 | null                                               \n",
      " med_salary                 | null                                               \n",
      " min_salary                 | null                                               \n",
      " pay_period                 | null                                               \n",
      " formatted_work_type        | Full-time                                          \n",
      " location                   | Beaver Dam, WI                                     \n",
      " applies                    | null                                               \n",
      " original_listed_time       | null                                               \n",
      " remote_allowed             | null                                               \n",
      " views                      | null                                               \n",
      " job_posting_url            | https://www.linkedin.com/jobs/view/3757940025/?... \n",
      " application_url            | https://www.click2apply.net/mXLQz5S5NEYEXsKjwHRdYq \n",
      " application_type           | OffsiteApply                                       \n",
      " expiry                     | null                                               \n",
      " closed_time                | null                                               \n",
      " formatted_experience_level | null                                               \n",
      " skills_desc                | null                                               \n",
      " listed_time                | null                                               \n",
      " posting_domain             | www.click2apply.net                                \n",
      " sponsored                  | 0                                                  \n",
      " work_type                  | FULL_TIME                                          \n",
      " currency                   | null                                               \n",
      " compensation_type          | null                                               \n",
      " scraped                    | 1699085420                                         \n",
      "-RECORD 2------------------------------------------------------------------------\n",
      " job_id                     | 3757938019                                         \n",
      " company_id                 | 474443                                             \n",
      " title                      | Manager, Engineering                               \n",
      " description                | \\nThe TSUBAKI name is synonymous with excellenc... \n",
      " max_salary                 | null                                               \n",
      " med_salary                 | null                                               \n",
      " min_salary                 | null                                               \n",
      " pay_period                 | null                                               \n",
      " formatted_work_type        | Full-time                                          \n",
      " location                   | Bessemer, AL                                       \n",
      " applies                    | null                                               \n",
      " original_listed_time       | null                                               \n",
      " remote_allowed             | null                                               \n",
      " views                      | null                                               \n",
      " job_posting_url            | https://www.linkedin.com/jobs/view/3757938019/?... \n",
      " application_url            | https://www.click2apply.net/LwbOykH2yAJdahB5Ah5Gzp \n",
      " application_type           | OffsiteApply                                       \n",
      " expiry                     | null                                               \n",
      " closed_time                | null                                               \n",
      " formatted_experience_level | null                                               \n",
      " skills_desc                | Bachelor's Degree in Mechanical Engineering pre... \n",
      " listed_time                | null                                               \n",
      " posting_domain             | www.click2apply.net                                \n",
      " sponsored                  | 0                                                  \n",
      " work_type                  | FULL_TIME                                          \n",
      " currency                   | null                                               \n",
      " compensation_type          | null                                               \n",
      " scraped                    | 1699085644                                         \n",
      "-RECORD 3------------------------------------------------------------------------\n",
      " job_id                     | 3757938018                                         \n",
      " company_id                 | 18213359                                           \n",
      " title                      | Cook                                               \n",
      " description                | descriptionTitle\\n\\n Looking for a great opport... \n",
      " max_salary                 | null                                               \n",
      " med_salary                 | 22.27                                              \n",
      " min_salary                 | null                                               \n",
      " pay_period                 | HOURLY                                             \n",
      " formatted_work_type        | Full-time                                          \n",
      " location                   | Aliso Viejo, CA                                    \n",
      " applies                    | null                                               \n",
      " original_listed_time       | null                                               \n",
      " remote_allowed             | null                                               \n",
      " views                      | 1                                                  \n",
      " job_posting_url            | https://www.linkedin.com/jobs/view/3757938018/?... \n",
      " application_url            | https://jobs.apploi.com/view/854782?utm_campaig... \n",
      " application_type           | OffsiteApply                                       \n",
      " expiry                     | null                                               \n",
      " closed_time                | null                                               \n",
      " formatted_experience_level | Entry level                                        \n",
      " skills_desc                | null                                               \n",
      " listed_time                | null                                               \n",
      " posting_domain             | jobs.apploi.com                                    \n",
      " sponsored                  | 0                                                  \n",
      " work_type                  | FULL_TIME                                          \n",
      " currency                   | USD                                                \n",
      " compensation_type          | BASE_SALARY                                        \n",
      " scraped                    | 1699087461                                         \n",
      "-RECORD 4------------------------------------------------------------------------\n",
      " job_id                     | 3757937095                                         \n",
      " company_id                 | 437225                                             \n",
      " title                      | Principal Cloud Security Architect (Remote)        \n",
      " description                | Job Summary\\nAt iHerb, we are on a mission to m... \n",
      " max_salary                 | 275834.0                                           \n",
      " med_salary                 | null                                               \n",
      " min_salary                 | 205956.0                                           \n",
      " pay_period                 | YEARLY                                             \n",
      " formatted_work_type        | Full-time                                          \n",
      " location                   | United States                                      \n",
      " applies                    | null                                               \n",
      " original_listed_time       | null                                               \n",
      " remote_allowed             | 1                                                  \n",
      " views                      | null                                               \n",
      " job_posting_url            | https://www.linkedin.com/jobs/view/3757937095/?... \n",
      " application_url            | https://careers.iherb.com/global/en/job/IHINGLO... \n",
      " application_type           | OffsiteApply                                       \n",
      " expiry                     | null                                               \n",
      " closed_time                | null                                               \n",
      " formatted_experience_level | Mid-Senior level                                   \n",
      " skills_desc                | null                                               \n",
      " listed_time                | null                                               \n",
      " posting_domain             | careers.iherb.com                                  \n",
      " sponsored                  | 0                                                  \n",
      " work_type                  | FULL_TIME                                          \n",
      " currency                   | USD                                                \n",
      " compensation_type          | BASE_SALARY                                        \n",
      " scraped                    | 1699085346                                         \n",
      "-RECORD 5------------------------------------------------------------------------\n",
      " job_id                     | 3757937037                                         \n",
      " company_id                 | 13727                                              \n",
      " title                      | Territory Manager - New Haven                      \n",
      " description                | Location: Remote, CT, United States of America\\... \n",
      " max_salary                 | null                                               \n",
      " med_salary                 | null                                               \n",
      " min_salary                 | null                                               \n",
      " pay_period                 | null                                               \n",
      " formatted_work_type        | Full-time                                          \n",
      " location                   | United States                                      \n",
      " applies                    | null                                               \n",
      " original_listed_time       | null                                               \n",
      " remote_allowed             | 1                                                  \n",
      " views                      | 16                                                 \n",
      " job_posting_url            | https://www.linkedin.com/jobs/view/3757937037/?... \n",
      " application_url            | https://www.zoll.com/contact/careers-at-zoll/ca... \n",
      " application_type           | OffsiteApply                                       \n",
      " expiry                     | null                                               \n",
      " closed_time                | null                                               \n",
      " formatted_experience_level | Mid-Senior level                                   \n",
      " skills_desc                | null                                               \n",
      " listed_time                | null                                               \n",
      " posting_domain             | www.zoll.com                                       \n",
      " sponsored                  | 0                                                  \n",
      " work_type                  | FULL_TIME                                          \n",
      " currency                   | null                                               \n",
      " compensation_type          | null                                               \n",
      " scraped                    | 1699137801                                         \n",
      "-RECORD 6------------------------------------------------------------------------\n",
      " job_id                     | 3757937004                                         \n",
      " company_id                 | 10515052                                           \n",
      " title                      | Auto Body Techncian                                \n",
      " description                | Company: Gerber Collision & Glass\\n\\nWELCOME TO... \n",
      " max_salary                 | null                                               \n",
      " med_salary                 | null                                               \n",
      " min_salary                 | null                                               \n",
      " pay_period                 | null                                               \n",
      " formatted_work_type        | Full-time                                          \n",
      " location                   | Daytona Beach, FL                                  \n",
      " applies                    | null                                               \n",
      " original_listed_time       | null                                               \n",
      " remote_allowed             | null                                               \n",
      " views                      | 1                                                  \n",
      " job_posting_url            | https://www.linkedin.com/jobs/view/3757937004/?... \n",
      " application_url            | https://boydgroup.wd1.myworkdayjobs.com/boydcar... \n",
      " application_type           | OffsiteApply                                       \n",
      " expiry                     | null                                               \n",
      " closed_time                | null                                               \n",
      " formatted_experience_level | Entry level                                        \n",
      " skills_desc                | null                                               \n",
      " listed_time                | null                                               \n",
      " posting_domain             | boydgroup.wd1.myworkdayjobs.com                    \n",
      " sponsored                  | 0                                                  \n",
      " work_type                  | FULL_TIME                                          \n",
      " currency                   | null                                               \n",
      " compensation_type          | null                                               \n",
      " scraped                    | 1699089473                                         \n",
      "-RECORD 7------------------------------------------------------------------------\n",
      " job_id                     | 3757936167                                         \n",
      " company_id                 | 2915                                               \n",
      " title                      | ACME D8- Asst Store Director (ASD) Sussex, NJ      \n",
      " description                | The First Assistant Store Director is actively ... \n",
      " max_salary                 | null                                               \n",
      " med_salary                 | null                                               \n",
      " min_salary                 | null                                               \n",
      " pay_period                 | null                                               \n",
      " formatted_work_type        | Full-time                                          \n",
      " location                   | Sussex, NJ                                         \n",
      " applies                    | null                                               \n",
      " original_listed_time       | null                                               \n",
      " remote_allowed             | null                                               \n",
      " views                      | 2                                                  \n",
      " job_posting_url            | https://www.linkedin.com/jobs/view/3757936167/?... \n",
      " application_url            | https://eofd.fa.us6.oraclecloud.com/hcmUI/Candi... \n",
      " application_type           | OffsiteApply                                       \n",
      " expiry                     | null                                               \n",
      " closed_time                | null                                               \n",
      " formatted_experience_level | Mid-Senior level                                   \n",
      " skills_desc                | null                                               \n",
      " listed_time                | null                                               \n",
      " posting_domain             | eofd.fa.us6.oraclecloud.com                        \n",
      " sponsored                  | 0                                                  \n",
      " work_type                  | FULL_TIME                                          \n",
      " currency                   | null                                               \n",
      " compensation_type          | null                                               \n",
      " scraped                    | 1699138852                                         \n",
      "-RECORD 8------------------------------------------------------------------------\n",
      " job_id                     | 3757936097                                         \n",
      " company_id                 | 18213359                                           \n",
      " title                      | Dishwasher                                         \n",
      " description                | descriptionTitle\\n\\n $2,000 Sign-on Bonus Guara... \n",
      " max_salary                 | null                                               \n",
      " med_salary                 | 19.3                                               \n",
      " min_salary                 | null                                               \n",
      " pay_period                 | HOURLY                                             \n",
      " formatted_work_type        | Full-time                                          \n",
      " location                   | Aliso Viejo, CA                                    \n",
      " applies                    | null                                               \n",
      " original_listed_time       | null                                               \n",
      " remote_allowed             | null                                               \n",
      " views                      | null                                               \n",
      " job_posting_url            | https://www.linkedin.com/jobs/view/3757936097/?... \n",
      " application_url            | https://jobs.apploi.com/view/861363?utm_campaig... \n",
      " application_type           | OffsiteApply                                       \n",
      " expiry                     | null                                               \n",
      " closed_time                | null                                               \n",
      " formatted_experience_level | Entry level                                        \n",
      " skills_desc                | null                                               \n",
      " listed_time                | null                                               \n",
      " posting_domain             | jobs.apploi.com                                    \n",
      " sponsored                  | 0                                                  \n",
      " work_type                  | FULL_TIME                                          \n",
      " currency                   | USD                                                \n",
      " compensation_type          | BASE_SALARY                                        \n",
      " scraped                    | 1699089324                                         \n",
      "-RECORD 9------------------------------------------------------------------------\n",
      " job_id                     | 3757936026                                         \n",
      " company_id                 | 634806                                             \n",
      " title                      | Instrumentation Quality Control Representative ... \n",
      " description                | Instrumentation Quality Control Representative\\... \n",
      " max_salary                 | null                                               \n",
      " med_salary                 | null                                               \n",
      " min_salary                 | null                                               \n",
      " pay_period                 | null                                               \n",
      " formatted_work_type        | Contract                                           \n",
      " location                   | United States                                      \n",
      " applies                    | 12                                                 \n",
      " original_listed_time       | null                                               \n",
      " remote_allowed             | 1                                                  \n",
      " views                      | 59                                                 \n",
      " job_posting_url            | https://www.linkedin.com/jobs/view/3757936026/?... \n",
      " application_url            | null                                               \n",
      " application_type           | SimpleOnsiteApply                                  \n",
      " expiry                     | null                                               \n",
      " closed_time                | null                                               \n",
      " formatted_experience_level | Entry level                                        \n",
      " skills_desc                | null                                               \n",
      " listed_time                | null                                               \n",
      " posting_domain             | jobs.stsigroup.com                                 \n",
      " sponsored                  | 0                                                  \n",
      " work_type                  | CONTRACT                                           \n",
      " currency                   | null                                               \n",
      " compensation_type          | null                                               \n",
      " scraped                    | 1699137876                                         \n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_posting.show(10, truncate=50, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------------------------------------------\n",
      " job_id                     | 3757940104                                         \n",
      " company_id                 | 553718                                             \n",
      " title                      | Hearing Care Provider                              \n",
      " description                | Overview\\n\\nHearingLife is a national hearing c... \n",
      " max_salary                 | null                                               \n",
      " med_salary                 | 5250.0                                             \n",
      " min_salary                 | null                                               \n",
      " pay_period                 | MONTHLY                                            \n",
      " formatted_work_type        | Full-time                                          \n",
      " location                   | Little River, SC                                   \n",
      " applies                    | null                                               \n",
      " original_listed_time       | 2023-11-04 09:26:40                                \n",
      " remote_allowed             | null                                               \n",
      " views                      | 9                                                  \n",
      " job_posting_url            | https://www.linkedin.com/jobs/view/3757940104/?... \n",
      " application_url            | https://careers-demant.icims.com/jobs/19601/hea... \n",
      " application_type           | OffsiteApply                                       \n",
      " expiry                     | 2023-12-04 08:53:20                                \n",
      " closed_time                | null                                               \n",
      " formatted_experience_level | Entry level                                        \n",
      " skills_desc                | null                                               \n",
      " listed_time                | 2023-11-04 09:26:40                                \n",
      " posting_domain             | careers-demant.icims.com                           \n",
      " sponsored                  | 0                                                  \n",
      " work_type                  | FULL_TIME                                          \n",
      " currency                   | USD                                                \n",
      " compensation_type          | BASE_SALARY                                        \n",
      " scraped                    | 1699138101                                         \n",
      "-RECORD 1------------------------------------------------------------------------\n",
      " job_id                     | 3757940025                                         \n",
      " company_id                 | 2192142                                            \n",
      " title                      | Shipping & Receiving Associate 2nd shift (Beave... \n",
      " description                | Metalcraft of Mayville\\nMetalcraft of Mayville ... \n",
      " max_salary                 | null                                               \n",
      " med_salary                 | null                                               \n",
      " min_salary                 | null                                               \n",
      " pay_period                 | null                                               \n",
      " formatted_work_type        | Full-time                                          \n",
      " location                   | Beaver Dam, WI                                     \n",
      " applies                    | null                                               \n",
      " original_listed_time       | 2023-11-04 06:40:00                                \n",
      " remote_allowed             | null                                               \n",
      " views                      | null                                               \n",
      " job_posting_url            | https://www.linkedin.com/jobs/view/3757940025/?... \n",
      " application_url            | https://www.click2apply.net/mXLQz5S5NEYEXsKjwHRdYq \n",
      " application_type           | OffsiteApply                                       \n",
      " expiry                     | 2023-12-04 08:53:20                                \n",
      " closed_time                | null                                               \n",
      " formatted_experience_level | null                                               \n",
      " skills_desc                | null                                               \n",
      " listed_time                | 2023-11-04 06:40:00                                \n",
      " posting_domain             | www.click2apply.net                                \n",
      " sponsored                  | 0                                                  \n",
      " work_type                  | FULL_TIME                                          \n",
      " currency                   | null                                               \n",
      " compensation_type          | null                                               \n",
      " scraped                    | 1699085420                                         \n",
      "-RECORD 2------------------------------------------------------------------------\n",
      " job_id                     | 3757938019                                         \n",
      " company_id                 | 474443                                             \n",
      " title                      | Manager, Engineering                               \n",
      " description                | \\nThe TSUBAKI name is synonymous with excellenc... \n",
      " max_salary                 | null                                               \n",
      " med_salary                 | null                                               \n",
      " min_salary                 | null                                               \n",
      " pay_period                 | null                                               \n",
      " formatted_work_type        | Full-time                                          \n",
      " location                   | Bessemer, AL                                       \n",
      " applies                    | null                                               \n",
      " original_listed_time       | 2023-11-04 06:40:00                                \n",
      " remote_allowed             | null                                               \n",
      " views                      | null                                               \n",
      " job_posting_url            | https://www.linkedin.com/jobs/view/3757938019/?... \n",
      " application_url            | https://www.click2apply.net/LwbOykH2yAJdahB5Ah5Gzp \n",
      " application_type           | OffsiteApply                                       \n",
      " expiry                     | 2023-12-04 08:53:20                                \n",
      " closed_time                | null                                               \n",
      " formatted_experience_level | null                                               \n",
      " skills_desc                | Bachelor's Degree in Mechanical Engineering pre... \n",
      " listed_time                | 2023-11-04 06:40:00                                \n",
      " posting_domain             | www.click2apply.net                                \n",
      " sponsored                  | 0                                                  \n",
      " work_type                  | FULL_TIME                                          \n",
      " currency                   | null                                               \n",
      " compensation_type          | null                                               \n",
      " scraped                    | 1699085644                                         \n",
      "-RECORD 3------------------------------------------------------------------------\n",
      " job_id                     | 3757938018                                         \n",
      " company_id                 | 18213359                                           \n",
      " title                      | Cook                                               \n",
      " description                | descriptionTitle\\n\\n Looking for a great opport... \n",
      " max_salary                 | null                                               \n",
      " med_salary                 | 22.27                                              \n",
      " min_salary                 | null                                               \n",
      " pay_period                 | HOURLY                                             \n",
      " formatted_work_type        | Full-time                                          \n",
      " location                   | Aliso Viejo, CA                                    \n",
      " applies                    | null                                               \n",
      " original_listed_time       | 2023-11-04 06:40:00                                \n",
      " remote_allowed             | null                                               \n",
      " views                      | 1                                                  \n",
      " job_posting_url            | https://www.linkedin.com/jobs/view/3757938018/?... \n",
      " application_url            | https://jobs.apploi.com/view/854782?utm_campaig... \n",
      " application_type           | OffsiteApply                                       \n",
      " expiry                     | 2023-12-04 08:53:20                                \n",
      " closed_time                | null                                               \n",
      " formatted_experience_level | Entry level                                        \n",
      " skills_desc                | null                                               \n",
      " listed_time                | 2023-11-04 06:40:00                                \n",
      " posting_domain             | jobs.apploi.com                                    \n",
      " sponsored                  | 0                                                  \n",
      " work_type                  | FULL_TIME                                          \n",
      " currency                   | USD                                                \n",
      " compensation_type          | BASE_SALARY                                        \n",
      " scraped                    | 1699087461                                         \n",
      "-RECORD 4------------------------------------------------------------------------\n",
      " job_id                     | 3757937095                                         \n",
      " company_id                 | 437225                                             \n",
      " title                      | Principal Cloud Security Architect (Remote)        \n",
      " description                | Job Summary\\nAt iHerb, we are on a mission to m... \n",
      " max_salary                 | 275834.0                                           \n",
      " med_salary                 | null                                               \n",
      " min_salary                 | 205956.0                                           \n",
      " pay_period                 | YEARLY                                             \n",
      " formatted_work_type        | Full-time                                          \n",
      " location                   | United States                                      \n",
      " applies                    | null                                               \n",
      " original_listed_time       | 2023-11-03 00:06:40                                \n",
      " remote_allowed             | 1                                                  \n",
      " views                      | null                                               \n",
      " job_posting_url            | https://www.linkedin.com/jobs/view/3757937095/?... \n",
      " application_url            | https://careers.iherb.com/global/en/job/IHINGLO... \n",
      " application_type           | OffsiteApply                                       \n",
      " expiry                     | 2023-12-04 08:53:20                                \n",
      " closed_time                | null                                               \n",
      " formatted_experience_level | Mid-Senior level                                   \n",
      " skills_desc                | null                                               \n",
      " listed_time                | 2023-11-04 09:26:40                                \n",
      " posting_domain             | careers.iherb.com                                  \n",
      " sponsored                  | 0                                                  \n",
      " work_type                  | FULL_TIME                                          \n",
      " currency                   | USD                                                \n",
      " compensation_type          | BASE_SALARY                                        \n",
      " scraped                    | 1699085346                                         \n",
      "-RECORD 5------------------------------------------------------------------------\n",
      " job_id                     | 3757937037                                         \n",
      " company_id                 | 13727                                              \n",
      " title                      | Territory Manager - New Haven                      \n",
      " description                | Location: Remote, CT, United States of America\\... \n",
      " max_salary                 | null                                               \n",
      " med_salary                 | null                                               \n",
      " min_salary                 | null                                               \n",
      " pay_period                 | null                                               \n",
      " formatted_work_type        | Full-time                                          \n",
      " location                   | United States                                      \n",
      " applies                    | null                                               \n",
      " original_listed_time       | 2023-10-31 02:40:00                                \n",
      " remote_allowed             | 1                                                  \n",
      " views                      | 16                                                 \n",
      " job_posting_url            | https://www.linkedin.com/jobs/view/3757937037/?... \n",
      " application_url            | https://www.zoll.com/contact/careers-at-zoll/ca... \n",
      " application_type           | OffsiteApply                                       \n",
      " expiry                     | 2023-12-04 08:53:20                                \n",
      " closed_time                | 2023-11-14 22:13:20                                \n",
      " formatted_experience_level | Mid-Senior level                                   \n",
      " skills_desc                | null                                               \n",
      " listed_time                | 2023-11-04 06:40:00                                \n",
      " posting_domain             | www.zoll.com                                       \n",
      " sponsored                  | 0                                                  \n",
      " work_type                  | FULL_TIME                                          \n",
      " currency                   | null                                               \n",
      " compensation_type          | null                                               \n",
      " scraped                    | 1699137801                                         \n",
      "-RECORD 6------------------------------------------------------------------------\n",
      " job_id                     | 3757937004                                         \n",
      " company_id                 | 10515052                                           \n",
      " title                      | Auto Body Techncian                                \n",
      " description                | Company: Gerber Collision & Glass\\n\\nWELCOME TO... \n",
      " max_salary                 | null                                               \n",
      " med_salary                 | null                                               \n",
      " min_salary                 | null                                               \n",
      " pay_period                 | null                                               \n",
      " formatted_work_type        | Full-time                                          \n",
      " location                   | Daytona Beach, FL                                  \n",
      " applies                    | null                                               \n",
      " original_listed_time       | 2023-11-04 06:40:00                                \n",
      " remote_allowed             | null                                               \n",
      " views                      | 1                                                  \n",
      " job_posting_url            | https://www.linkedin.com/jobs/view/3757937004/?... \n",
      " application_url            | https://boydgroup.wd1.myworkdayjobs.com/boydcar... \n",
      " application_type           | OffsiteApply                                       \n",
      " expiry                     | 2023-12-04 08:53:20                                \n",
      " closed_time                | null                                               \n",
      " formatted_experience_level | Entry level                                        \n",
      " skills_desc                | null                                               \n",
      " listed_time                | 2023-11-04 06:40:00                                \n",
      " posting_domain             | boydgroup.wd1.myworkdayjobs.com                    \n",
      " sponsored                  | 0                                                  \n",
      " work_type                  | FULL_TIME                                          \n",
      " currency                   | null                                               \n",
      " compensation_type          | null                                               \n",
      " scraped                    | 1699089473                                         \n",
      "-RECORD 7------------------------------------------------------------------------\n",
      " job_id                     | 3757936167                                         \n",
      " company_id                 | 2915                                               \n",
      " title                      | ACME D8- Asst Store Director (ASD) Sussex, NJ      \n",
      " description                | The First Assistant Store Director is actively ... \n",
      " max_salary                 | null                                               \n",
      " med_salary                 | null                                               \n",
      " min_salary                 | null                                               \n",
      " pay_period                 | null                                               \n",
      " formatted_work_type        | Full-time                                          \n",
      " location                   | Sussex, NJ                                         \n",
      " applies                    | null                                               \n",
      " original_listed_time       | 2023-10-10 06:40:00                                \n",
      " remote_allowed             | null                                               \n",
      " views                      | 2                                                  \n",
      " job_posting_url            | https://www.linkedin.com/jobs/view/3757936167/?... \n",
      " application_url            | https://eofd.fa.us6.oraclecloud.com/hcmUI/Candi... \n",
      " application_type           | OffsiteApply                                       \n",
      " expiry                     | 2023-12-04 08:53:20                                \n",
      " closed_time                | null                                               \n",
      " formatted_experience_level | Mid-Senior level                                   \n",
      " skills_desc                | null                                               \n",
      " listed_time                | 2023-11-04 09:26:40                                \n",
      " posting_domain             | eofd.fa.us6.oraclecloud.com                        \n",
      " sponsored                  | 0                                                  \n",
      " work_type                  | FULL_TIME                                          \n",
      " currency                   | null                                               \n",
      " compensation_type          | null                                               \n",
      " scraped                    | 1699138852                                         \n",
      "-RECORD 8------------------------------------------------------------------------\n",
      " job_id                     | 3757936097                                         \n",
      " company_id                 | 18213359                                           \n",
      " title                      | Dishwasher                                         \n",
      " description                | descriptionTitle\\n\\n $2,000 Sign-on Bonus Guara... \n",
      " max_salary                 | null                                               \n",
      " med_salary                 | 19.3                                               \n",
      " min_salary                 | null                                               \n",
      " pay_period                 | HOURLY                                             \n",
      " formatted_work_type        | Full-time                                          \n",
      " location                   | Aliso Viejo, CA                                    \n",
      " applies                    | null                                               \n",
      " original_listed_time       | 2023-11-04 06:40:00                                \n",
      " remote_allowed             | null                                               \n",
      " views                      | null                                               \n",
      " job_posting_url            | https://www.linkedin.com/jobs/view/3757936097/?... \n",
      " application_url            | https://jobs.apploi.com/view/861363?utm_campaig... \n",
      " application_type           | OffsiteApply                                       \n",
      " expiry                     | 2023-12-04 08:53:20                                \n",
      " closed_time                | null                                               \n",
      " formatted_experience_level | Entry level                                        \n",
      " skills_desc                | null                                               \n",
      " listed_time                | 2023-11-04 06:40:00                                \n",
      " posting_domain             | jobs.apploi.com                                    \n",
      " sponsored                  | 0                                                  \n",
      " work_type                  | FULL_TIME                                          \n",
      " currency                   | USD                                                \n",
      " compensation_type          | BASE_SALARY                                        \n",
      " scraped                    | 1699089324                                         \n",
      "-RECORD 9------------------------------------------------------------------------\n",
      " job_id                     | 3757936026                                         \n",
      " company_id                 | 634806                                             \n",
      " title                      | Instrumentation Quality Control Representative ... \n",
      " description                | Instrumentation Quality Control Representative\\... \n",
      " max_salary                 | null                                               \n",
      " med_salary                 | null                                               \n",
      " min_salary                 | null                                               \n",
      " pay_period                 | null                                               \n",
      " formatted_work_type        | Contract                                           \n",
      " location                   | United States                                      \n",
      " applies                    | 12                                                 \n",
      " original_listed_time       | 2023-11-04 06:40:00                                \n",
      " remote_allowed             | 1                                                  \n",
      " views                      | 59                                                 \n",
      " job_posting_url            | https://www.linkedin.com/jobs/view/3757936026/?... \n",
      " application_url            | null                                               \n",
      " application_type           | SimpleOnsiteApply                                  \n",
      " expiry                     | 2024-01-03 08:20:00                                \n",
      " closed_time                | null                                               \n",
      " formatted_experience_level | Entry level                                        \n",
      " skills_desc                | null                                               \n",
      " listed_time                | 2023-11-04 20:33:20                                \n",
      " posting_domain             | jobs.stsigroup.com                                 \n",
      " sponsored                  | 0                                                  \n",
      " work_type                  | CONTRACT                                           \n",
      " currency                   | null                                               \n",
      " compensation_type          | null                                               \n",
      " scraped                    | 1699137876                                         \n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a list of your timestamp columns\n",
    "timestamp_columns = [\"original_listed_time\", \"expiry\", \"closed_time\", \"listed_time\"]\n",
    "\n",
    "# Convert from Unix time in milliseconds to a proper timestamp\n",
    "# Loop through the list and apply the transformation to each column\n",
    "for column_name in timestamp_columns:\n",
    "    df_posting = df_posting.withColumn(\n",
    "        column_name,\n",
    "        (col(column_name) / 1000).cast(\"timestamp\")\n",
    "    )\n",
    "\n",
    "# Show the dataframe\n",
    "df_posting.show(10, truncate=50, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posting = df_posting.repartition(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_posting.write.parquet(\"./data/pq-linkedin-job-postings/pq_job_postings/\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### company_details/companies.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------\n",
      " company_id   | 1009       \n",
      " name         | IBM        \n",
      " description  | At IBM,... \n",
      " company_size | 7          \n",
      " state        | NY         \n",
      " country      | US         \n",
      " city         | Armonk,... \n",
      " zip_code     | 10504      \n",
      " address      | Interna... \n",
      " url          | https:/... \n",
      "-RECORD 1------------------\n",
      " company_id   | 1016       \n",
      " name         | GE Heal... \n",
      " description  | Every d... \n",
      " company_size | 7          \n",
      " state        | 0          \n",
      " country      | US         \n",
      " city         | Chicago    \n",
      " zip_code     | 0          \n",
      " address      | -          \n",
      " url          | https:/... \n",
      "-RECORD 2------------------\n",
      " company_id   | 1021       \n",
      " name         | GE Power   \n",
      " description  | GE Powe... \n",
      " company_size | 7          \n",
      " state        | NY         \n",
      " country      | US         \n",
      " city         | Schenec... \n",
      " zip_code     | 12345      \n",
      " address      | 1 River... \n",
      " url          | https:/... \n",
      "-RECORD 3------------------\n",
      " company_id   | 1025       \n",
      " name         | Hewlett... \n",
      " description  | Officia... \n",
      " company_size | 7          \n",
      " state        | Texas      \n",
      " country      | US         \n",
      " city         | Houston    \n",
      " zip_code     | 77389      \n",
      " address      | 1701 E ... \n",
      " url          | https:/... \n",
      "-RECORD 4------------------\n",
      " company_id   | 1028       \n",
      " name         | Oracle     \n",
      " description  | Were a... \n",
      " company_size | 7          \n",
      " state        | Texas      \n",
      " country      | US         \n",
      " city         | Austin     \n",
      " zip_code     | 78741      \n",
      " address      | 2300 Or... \n",
      " url          | https:/... \n",
      "-RECORD 5------------------\n",
      " company_id   | 1033       \n",
      " name         | Accenture  \n",
      " description  | Accentu... \n",
      " company_size | 7          \n",
      " state        | 0          \n",
      " country      | IE         \n",
      " city         | Dublin 2   \n",
      " zip_code     | 0          \n",
      " address      | Grand C... \n",
      " url          | https:/... \n",
      "-RECORD 6------------------\n",
      " company_id   | 1038       \n",
      " name         | Deloitte   \n",
      " description  | Deloitt... \n",
      " company_size | 7          \n",
      " state        | 0          \n",
      " country      | OO         \n",
      " city         | Worldwide  \n",
      " zip_code     | 0          \n",
      " address      | Worldwide  \n",
      " url          | https:/... \n",
      "-RECORD 7------------------\n",
      " company_id   | 1043       \n",
      " name         | Siemens    \n",
      " description  | Siemens... \n",
      " company_size | 7          \n",
      " state        | 0          \n",
      " country      | DE         \n",
      " city         | Munich     \n",
      " zip_code     | 80333      \n",
      " address      | Werner-... \n",
      " url          | https:/... \n",
      "-RECORD 8------------------\n",
      " company_id   | 1044       \n",
      " name         | PwC        \n",
      " description  | At PwC,... \n",
      " company_size | 7          \n",
      " state        | 0          \n",
      " country      | GB         \n",
      " city         | 0          \n",
      " zip_code     | 0          \n",
      " address      | 1 Emban... \n",
      " url          | https:/... \n",
      "-RECORD 9------------------\n",
      " company_id   | 1052       \n",
      " name         | AT&T       \n",
      " description  | We unde... \n",
      " company_size | 7          \n",
      " state        | TX         \n",
      " country      | US         \n",
      " city         | Dallas     \n",
      " zip_code     | 75202      \n",
      " address      | 208 S. ... \n",
      " url          | https:/... \n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "companies_schema=StructType([\n",
    "    StructField(\"company_id\", StringType(), True), \n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"description\", StringType(), True),\n",
    "    StructField(\"company_size\", IntegerType(), True),  \n",
    "    StructField(\"state\", StringType(), True),\n",
    "    StructField(\"country\", StringType(), True),\n",
    "    StructField(\"city\", StringType(), True),\n",
    "    StructField(\"zip_code\", StringType(), True), \n",
    "    StructField(\"address\", StringType(), True),\n",
    "    StructField(\"url\", StringType(), True)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "df_companies = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(companies_schema) \\\n",
    "    .option(\"escape\", \"\\\"\") \\\n",
    "    .option(\"multiline\", \"true\") \\\n",
    "    .csv(\"./data/linkedin-job-postings/company_details/companies.csv\") \n",
    "\n",
    "\n",
    "df_companies.show(10, truncate=10, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_companies.repartition(5).write.parquet(\"./data/pq-linkedin-job-postings/pq_companies/\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### company_details/company_industries.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|company_id|            industry|\n",
      "+----------+--------------------+\n",
      "|  81149246|    Higher Education|\n",
      "|  10033339|Information Techn...|\n",
      "|   6049228|          Accounting|\n",
      "|   2641066|Electrical & Elec...|\n",
      "|  96649998|Marketing & Adver...|\n",
      "|  82684341|Hospital & Health...|\n",
      "|  82296828|Information Techn...|\n",
      "|  86746333|Logistics & Suppl...|\n",
      "|    718651|    Medical Practice|\n",
      "|   4781041|  Mental Health Care|\n",
      "+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "company_industry_schema=StructType([\n",
    "    StructField(\"company_id\", StringType(), True), \n",
    "    StructField(\"industry\", StringType(), True)\n",
    "])\n",
    "\n",
    "\n",
    "df_company_industry = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(company_industry_schema) \\\n",
    "    .csv(\"./data/linkedin-job-postings/company_details/company_industries.csv\") \n",
    "\n",
    "\n",
    "df_company_industry.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_company_industry.repartition(2).write.parquet(\"./data/pq-linkedin-job-postings/pq_company_industries/\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### company_details/employee_counts.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------+--------------------+\n",
      "|company_id|employee_count|follower_count|       time_recorded|\n",
      "+----------+--------------+--------------+--------------------+\n",
      "|  81149246|             6|            91|1.6926446442779734E9|\n",
      "|  10033339|             3|           187|1.6926446442779734E9|\n",
      "|   6049228|            20|            82|1.6926446451013184E9|\n",
      "|   2641066|            45|          2336|1.6926446459232166E9|\n",
      "|  96649998|             0|             2|1.6926446459242187E9|\n",
      "|  82684341|             3|           128|1.6926446463704655E9|\n",
      "|  82296828|             0|            64|1.6926446463704655E9|\n",
      "|  86746333|            11|           478|1.6926446468182244E9|\n",
      "|    718651|             5|            22|1.6926446471765628E9|\n",
      "|   4781041|            14|            17|  1.69264464762722E9|\n",
      "+----------+--------------+--------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee_schema=StructType([\n",
    "    StructField(\"company_id\", StringType(), True),\n",
    "    StructField(\"employee_count\", IntegerType(), True),\n",
    "    StructField(\"follower_count\", IntegerType(), True),\n",
    "    StructField(\"time_recorded\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "df_employee_counts = spark.read \\\n",
    "    .schema(employee_schema) \\\n",
    "    .csv(\"./data/linkedin-job-postings/company_details/employee_counts.csv\", header=True)\n",
    "\n",
    "df_employee_counts.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------+-------------+\n",
      "|company_id|employee_count|follower_count|time_recorded|\n",
      "+----------+--------------+--------------+-------------+\n",
      "|  81149246|             6|            91|   1692644644|\n",
      "|  10033339|             3|           187|   1692644644|\n",
      "|   6049228|            20|            82|   1692644645|\n",
      "|   2641066|            45|          2336|   1692644645|\n",
      "|  96649998|             0|             2|   1692644645|\n",
      "|  82684341|             3|           128|   1692644646|\n",
      "|  82296828|             0|            64|   1692644646|\n",
      "|  86746333|            11|           478|   1692644646|\n",
      "|    718651|             5|            22|   1692644647|\n",
      "|   4781041|            14|            17|   1692644647|\n",
      "+----------+--------------+--------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Floor the 'time_recorded' column to remove decimal part, then cast to long\n",
    "df_employee_counts = df_employee_counts.withColumn(\n",
    "    \"time_recorded\",\n",
    "    floor(col(\"time_recorded\")).cast(\"long\")\n",
    ")\n",
    "\n",
    "df_employee_counts.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------+-------------------+\n",
      "|company_id|employee_count|follower_count|      time_recorded|\n",
      "+----------+--------------+--------------+-------------------+\n",
      "|  81149246|             6|            91|2023-08-21 19:04:04|\n",
      "|  10033339|             3|           187|2023-08-21 19:04:04|\n",
      "|   6049228|            20|            82|2023-08-21 19:04:05|\n",
      "|   2641066|            45|          2336|2023-08-21 19:04:05|\n",
      "|  96649998|             0|             2|2023-08-21 19:04:05|\n",
      "|  82684341|             3|           128|2023-08-21 19:04:06|\n",
      "|  82296828|             0|            64|2023-08-21 19:04:06|\n",
      "|  86746333|            11|           478|2023-08-21 19:04:06|\n",
      "|    718651|             5|            22|2023-08-21 19:04:07|\n",
      "|   4781041|            14|            17|2023-08-21 19:04:07|\n",
      "+----------+--------------+--------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now convert from Unix time in seconds to a proper timestamp\n",
    "df_employee_counts = df_employee_counts.withColumn(\n",
    "    \"time_recorded\",\n",
    "    from_unixtime(col(\"time_recorded\")).cast(\"timestamp\")\n",
    ")\n",
    "\n",
    "df_employee_counts.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- company_id: string (nullable = true)\n",
      " |-- employee_count: integer (nullable = true)\n",
      " |-- follower_count: integer (nullable = true)\n",
      " |-- time_recorded: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_employee_counts.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_employee_counts.repartition(5).write.parquet(\"./data/pq-linkedin-job-postings/pq_employee/\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### company_details/company_specialities.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|company_id|          speciality|\n",
      "+----------+--------------------+\n",
      "|  81149246|Childrens Music E...|\n",
      "|  81149246|Foundational Musi...|\n",
      "|  81149246| Child Music Lessons|\n",
      "|  81149246|social emotional ...|\n",
      "|  81149246|social emotional ...|\n",
      "|  81149246|           education|\n",
      "|  81149246|formative assessment|\n",
      "|  81149246|   expanded learning|\n",
      "|  81149246| enrichment programs|\n",
      "|  10033339|          SharePoint|\n",
      "+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "company_specialities_schema=StructType([\n",
    "    StructField(\"company_id\", StringType(), True),\n",
    "    StructField(\"speciality\", StringType(), True)\n",
    "])\n",
    "\n",
    "df_company_specialities = spark.read \\\n",
    "    .schema(company_specialities_schema) \\\n",
    "    .csv(\"./data/linkedin-job-postings/company_details/company_specialities.csv\", header=True)\n",
    "\n",
    "df_company_specialities.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_company_specialities.repartition(5).write.parquet(\"./data/pq-linkedin-job-postings/pq_company_specialities/\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### job_details/job_industries.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 0:>                                                          (0 + 1) / 1]\r\n",
      "\r\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|    job_id|industry_id|\n",
      "+----------+-----------+\n",
      "|3378133231|         68|\n",
      "|3497509795|         96|\n",
      "|3690843087|         47|\n",
      "|3691775263|        112|\n",
      "|3691779379|         80|\n",
      "|3691786992|         14|\n",
      "|3691789797|         96|\n",
      "|3691792844|        116|\n",
      "|3691793575|         13|\n",
      "|3691794313|         87|\n",
      "+----------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_job_industries = spark.read \\\n",
    "    .csv(\"./data/linkedin-job-postings/job_details/job_industries.csv\", header=True)\n",
    "\n",
    "df_job_industries.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- job_id: string (nullable = true)\n",
      " |-- industry_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_job_industries.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job_industries.repartition(5).write.parquet(\"./data/pq-linkedin-job-postings/pq_job_industries/\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### job_details/job_skills.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|    job_id|skill_abr|\n",
      "+----------+---------+\n",
      "|3690843087|     ACCT|\n",
      "|3690843087|      FIN|\n",
      "|3691763971|     MGMT|\n",
      "|3691763971|     MNFC|\n",
      "|3691775263|     MGMT|\n",
      "|3691775263|     MNFC|\n",
      "|3691786992|     HCPR|\n",
      "|3691789797|     MGMT|\n",
      "|3691789797|     MNFC|\n",
      "|3691789919|     HCPR|\n",
      "+----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_job_skills = spark.read \\\n",
    "    .csv(\"./data/linkedin-job-postings/job_details/job_skills.csv\", header=True)\n",
    "\n",
    "df_job_skills.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- job_id: string (nullable = true)\n",
      " |-- skill_abr: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_job_skills.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job_skills.repartition(5).write.parquet(\"./data/pq-linkedin-job-postings/pq_job_skills/\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### job_details/salaries.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary_id</th>\n",
       "      <th>job_id</th>\n",
       "      <th>max_salary</th>\n",
       "      <th>med_salary</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>pay_period</th>\n",
       "      <th>currency</th>\n",
       "      <th>compensation_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3378133231</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>HOURLY</td>\n",
       "      <td>USD</td>\n",
       "      <td>BASE_SALARY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3690843087</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>YEARLY</td>\n",
       "      <td>USD</td>\n",
       "      <td>BASE_SALARY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3691794313</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>HOURLY</td>\n",
       "      <td>USD</td>\n",
       "      <td>BASE_SALARY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3691795389</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68000.0</td>\n",
       "      <td>YEARLY</td>\n",
       "      <td>USD</td>\n",
       "      <td>BASE_SALARY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3691797089</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>HOURLY</td>\n",
       "      <td>USD</td>\n",
       "      <td>BASE_SALARY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   salary_id      job_id  max_salary  med_salary  min_salary pay_period  \\\n",
       "0          1  3378133231        30.0         NaN        22.0     HOURLY   \n",
       "1          2  3690843087     65000.0         NaN     55000.0     YEARLY   \n",
       "2          3  3691794313        22.0         NaN        19.0     HOURLY   \n",
       "3          4  3691795389     70000.0         NaN     68000.0     YEARLY   \n",
       "4          5  3691797089        22.0         NaN        18.0     HOURLY   \n",
       "\n",
       "  currency compensation_type  \n",
       "0      USD       BASE_SALARY  \n",
       "1      USD       BASE_SALARY  \n",
       "2      USD       BASE_SALARY  \n",
       "3      USD       BASE_SALARY  \n",
       "4      USD       BASE_SALARY  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_salaries = pd.read_csv(\"./data/linkedin-job-postings/job_details/salaries.csv\")\n",
    "df_salaries.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+----------+----------+----------+----------+--------+-----------------+\n",
      "|salary_id|    job_id|max_salary|med_salary|min_salary|pay_period|currency|compensation_type|\n",
      "+---------+----------+----------+----------+----------+----------+--------+-----------------+\n",
      "|        1|3378133231|      30.0|      null|      22.0|    HOURLY|     USD|      BASE_SALARY|\n",
      "|        2|3690843087|   65000.0|      null|   55000.0|    YEARLY|     USD|      BASE_SALARY|\n",
      "|        3|3691794313|      22.0|      null|      19.0|    HOURLY|     USD|      BASE_SALARY|\n",
      "|        4|3691795389|   70000.0|      null|   68000.0|    YEARLY|     USD|      BASE_SALARY|\n",
      "|        5|3691797089|      22.0|      null|      18.0|    HOURLY|     USD|      BASE_SALARY|\n",
      "|        6|3691797249|      26.0|      null|      21.0|    HOURLY|     USD|      BASE_SALARY|\n",
      "|        7|3691797979|  120250.0|      null|   98924.0|    YEARLY|     USD|      BASE_SALARY|\n",
      "|        8|3691798879|   85000.0|      null|   75000.0|    YEARLY|     USD|      BASE_SALARY|\n",
      "|        9|3691799449|  135000.0|      null|  120000.0|    YEARLY|     USD|      BASE_SALARY|\n",
      "|       10|3691799471|  135300.0|      null|   98400.0|    YEARLY|     USD|      BASE_SALARY|\n",
      "+---------+----------+----------+----------+----------+----------+--------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the Spark schema\n",
    "salary_schema = StructType([\n",
    "    StructField(\"salary_id\", StringType(), True),\n",
    "    StructField(\"job_id\", StringType(), True),\n",
    "    StructField(\"max_salary\", FloatType(), True),\n",
    "    StructField(\"med_salary\", FloatType(), True),\n",
    "    StructField(\"min_salary\", FloatType(), True),\n",
    "    StructField(\"pay_period\", StringType(), True),\n",
    "    StructField(\"currency\", StringType(), True),\n",
    "    StructField(\"compensation_type\", StringType(), True)\n",
    "])\n",
    "\n",
    "\n",
    "df_salaries = spark.read \\\n",
    "    .schema(salary_schema) \\\n",
    "    .csv(\"./data/linkedin-job-postings/job_details/salaries.csv\", header=True)\n",
    "\n",
    "df_salaries.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salaries.repartition(5).write.parquet(\"./data/pq-linkedin-job-postings/pq_salaries/\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### job_details/benefits.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>inferred</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3690843087</td>\n",
       "      <td>0</td>\n",
       "      <td>Medical insurance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3690843087</td>\n",
       "      <td>0</td>\n",
       "      <td>Dental insurance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3690843087</td>\n",
       "      <td>0</td>\n",
       "      <td>401(k)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3690843087</td>\n",
       "      <td>0</td>\n",
       "      <td>Paid maternity leave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3690843087</td>\n",
       "      <td>0</td>\n",
       "      <td>Disability insurance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       job_id  inferred                  type\n",
       "0  3690843087         0     Medical insurance\n",
       "1  3690843087         0      Dental insurance\n",
       "2  3690843087         0                401(k)\n",
       "3  3690843087         0  Paid maternity leave\n",
       "4  3690843087         0  Disability insurance"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_benefits = pd.read_csv(\"./data/linkedin-job-postings/job_details/benefits.csv\")\n",
    "df_benefits.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|    job_id|inferred|                type|\n",
      "+----------+--------+--------------------+\n",
      "|3690843087|       0|   Medical insurance|\n",
      "|3690843087|       0|    Dental insurance|\n",
      "|3690843087|       0|              401(k)|\n",
      "|3690843087|       0|Paid maternity leave|\n",
      "|3690843087|       0|Disability insurance|\n",
      "|3690843087|       0|    Vision insurance|\n",
      "|3691763971|       1|    Dental insurance|\n",
      "|3691763971|       1|Disability insurance|\n",
      "|3691763971|       1|              401(k)|\n",
      "|3691775263|       0|   Medical insurance|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "benefit_schema = StructType([\n",
    "    StructField(\"job_id\", StringType(), True),\n",
    "    StructField(\"inferred\", StringType(), True),\n",
    "    StructField(\"type\", StringType(), True)\n",
    "])\n",
    "\n",
    "\n",
    "df_benefit = spark.read \\\n",
    "    .schema(benefit_schema) \\\n",
    "    .csv(\"./data/linkedin-job-postings/job_details/benefits.csv\", header=True)\n",
    "\n",
    "df_benefit.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benefit.repartition(5).write.parquet(\"./data/pq-linkedin-job-postings/pq_benefits/\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### maps/industries.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+\n",
      "|industry_id|       industry_name|\n",
      "+-----------+--------------------+\n",
      "|          1|Defense and Space...|\n",
      "|          3|Computer Hardware...|\n",
      "|          4|Software Development|\n",
      "|          5|Computer Networki...|\n",
      "|          6|Technology, Infor...|\n",
      "|          7|Semiconductor Man...|\n",
      "|          8|  Telecommunications|\n",
      "|          9|        Law Practice|\n",
      "|         10|      Legal Services|\n",
      "|         11|Business Consulti...|\n",
      "+-----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "industry_schema = StructType([\n",
    "    StructField(\"industry_id\", StringType(), True),\n",
    "    StructField(\"industry_name\", StringType(), True)\n",
    "])\n",
    "\n",
    "\n",
    "df_industry = spark.read \\\n",
    "    .schema(industry_schema) \\\n",
    "    .csv(\"./data/linkedin-job-postings/maps/industries.csv\", header=True)\n",
    "\n",
    "df_industry.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_industry.write.parquet(\"./data/pq-linkedin-job-postings/pq_industries/\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### maps/skills.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|skill_abr|        skill_name|\n",
      "+---------+------------------+\n",
      "|     PRCH|        Purchasing|\n",
      "|     SUPL|      Supply Chain|\n",
      "|       PR|  Public Relations|\n",
      "|      SCI|           Science|\n",
      "|     STRA| Strategy/Planning|\n",
      "|      WRT|   Writing/Editing|\n",
      "|       QA| Quality Assurance|\n",
      "|     DIST|      Distribution|\n",
      "|     PROD|        Production|\n",
      "|     PRJM|Project Management|\n",
      "+---------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "skills_schema = StructType([\n",
    "    StructField(\"skill_abr\", StringType(), True),\n",
    "    StructField(\"skill_name\", StringType(), True)\n",
    "])\n",
    "\n",
    "\n",
    "df_skills = spark.read \\\n",
    "    .schema(skills_schema) \\\n",
    "    .csv(\"./data/linkedin-job-postings/maps/skills.csv\", header=True)\n",
    "\n",
    "df_skills.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_skills.write.parquet(\"./data/pq-linkedin-job-postings/pq_skills/\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
